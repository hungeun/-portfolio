{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abec4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac13d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>OVERAGE</th>\n",
       "      <th>LEFTOVER</th>\n",
       "      <th>HOUSE</th>\n",
       "      <th>HANDSET_PRICE</th>\n",
       "      <th>OVER_15MINS_CALLS_PER_MONTH</th>\n",
       "      <th>AVERAGE_CALL_DURATION</th>\n",
       "      <th>REPORTED_SATISFACTION</th>\n",
       "      <th>REPORTED_USAGE_LEVEL</th>\n",
       "      <th>CONSIDERING_CHANGE_OF_PLAN</th>\n",
       "      <th>CHURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>544</td>\n",
       "      <td>1</td>\n",
       "      <td>47711</td>\n",
       "      <td>183</td>\n",
       "      <td>17</td>\n",
       "      <td>730589.0</td>\n",
       "      <td>192</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>unsat</td>\n",
       "      <td>little</td>\n",
       "      <td>considering</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>74132</td>\n",
       "      <td>191</td>\n",
       "      <td>43</td>\n",
       "      <td>535092.0</td>\n",
       "      <td>349</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>unsat</td>\n",
       "      <td>very_little</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3134</td>\n",
       "      <td>1</td>\n",
       "      <td>150419</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>204004.0</td>\n",
       "      <td>682</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>unsat</td>\n",
       "      <td>very_high</td>\n",
       "      <td>considering</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12523</td>\n",
       "      <td>0</td>\n",
       "      <td>159567</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>281969.0</td>\n",
       "      <td>634</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>very_unsat</td>\n",
       "      <td>very_high</td>\n",
       "      <td>never_thought</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2374</td>\n",
       "      <td>1</td>\n",
       "      <td>23392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>216707.0</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>unsat</td>\n",
       "      <td>very_little</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  COLLEGE  INCOME  OVERAGE  LEFTOVER     HOUSE  HANDSET_PRICE  \\\n",
       "0    544        1   47711      183        17  730589.0            192   \n",
       "1    689        0   74132      191        43  535092.0            349   \n",
       "2   3134        1  150419        0        14  204004.0            682   \n",
       "3  12523        0  159567        0        58  281969.0            634   \n",
       "4   2374        1   23392        0         0  216707.0            233   \n",
       "\n",
       "   OVER_15MINS_CALLS_PER_MONTH  AVERAGE_CALL_DURATION REPORTED_SATISFACTION  \\\n",
       "0                           19                      5                 unsat   \n",
       "1                           15                      2                 unsat   \n",
       "2                            0                      6                 unsat   \n",
       "3                            1                      1            very_unsat   \n",
       "4                            0                     15                 unsat   \n",
       "\n",
       "  REPORTED_USAGE_LEVEL CONSIDERING_CHANGE_OF_PLAN  CHURN  \n",
       "0               little                considering      0  \n",
       "1          very_little                         no      1  \n",
       "2            very_high                considering      0  \n",
       "3            very_high              never_thought      0  \n",
       "4          very_little                         no      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"https://raw.githubusercontent.com/DA4BAM/dataset/master/mobile_NA2.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa971fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'CHURN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7256ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(target, axis = 1)\n",
    "y = data.loc[:, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ea1900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('CHURN of Corr')\n",
    "\n",
    "data.drop(\"CHURN\", axis = 1).corrwith(data.CHURN).sort_values().plot(kind='barh', figsize = (10, 12))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceaa7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 그림에서 'id','AVERAGE_CALL_DURATION','COLLEGE' 하위 3개  \n",
    "# p.value값을 보고 'REPORTED_SATISFACTION','CONSIDERING_CHANGE_OF_PLAN' 삭제\n",
    "\n",
    "x.drop(['id','AVERAGE_CALL_DURATION','COLLEGE','REPORTED_SATISFACTION','CONSIDERING_CHANGE_OF_PLAN'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29f7f7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCOME                           0\n",
       "OVERAGE                          0\n",
       "LEFTOVER                         0\n",
       "HOUSE                          215\n",
       "HANDSET_PRICE                    0\n",
       "OVER_15MINS_CALLS_PER_MONTH      0\n",
       "REPORTED_USAGE_LEVEL             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce491aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCOME</th>\n",
       "      <th>OVERAGE</th>\n",
       "      <th>LEFTOVER</th>\n",
       "      <th>HOUSE</th>\n",
       "      <th>HANDSET_PRICE</th>\n",
       "      <th>OVER_15MINS_CALLS_PER_MONTH</th>\n",
       "      <th>REPORTED_USAGE_LEVEL_high</th>\n",
       "      <th>REPORTED_USAGE_LEVEL_little</th>\n",
       "      <th>REPORTED_USAGE_LEVEL_very_high</th>\n",
       "      <th>REPORTED_USAGE_LEVEL_very_little</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47711</td>\n",
       "      <td>183</td>\n",
       "      <td>17</td>\n",
       "      <td>730589.0</td>\n",
       "      <td>192</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74132</td>\n",
       "      <td>191</td>\n",
       "      <td>43</td>\n",
       "      <td>535092.0</td>\n",
       "      <td>349</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150419</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>204004.0</td>\n",
       "      <td>682</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159567</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>281969.0</td>\n",
       "      <td>634</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>216707.0</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INCOME  OVERAGE  LEFTOVER     HOUSE  HANDSET_PRICE  \\\n",
       "0   47711      183        17  730589.0            192   \n",
       "1   74132      191        43  535092.0            349   \n",
       "2  150419        0        14  204004.0            682   \n",
       "3  159567        0        58  281969.0            634   \n",
       "4   23392        0         0  216707.0            233   \n",
       "\n",
       "   OVER_15MINS_CALLS_PER_MONTH  REPORTED_USAGE_LEVEL_high  \\\n",
       "0                           19                          0   \n",
       "1                           15                          0   \n",
       "2                            0                          0   \n",
       "3                            1                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   REPORTED_USAGE_LEVEL_little  REPORTED_USAGE_LEVEL_very_high  \\\n",
       "0                            1                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               1   \n",
       "3                            0                               1   \n",
       "4                            0                               0   \n",
       "\n",
       "   REPORTED_USAGE_LEVEL_very_little  \n",
       "0                                 0  \n",
       "1                                 1  \n",
       "2                                 0  \n",
       "3                                 0  \n",
       "4                                 1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가변수화 \n",
    "\n",
    "dum_cols = ['REPORTED_USAGE_LEVEL']\n",
    "\n",
    "x = pd.get_dummies(x, columns = dum_cols ,drop_first = True)\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbde769e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCOME                              0\n",
       "OVERAGE                             0\n",
       "LEFTOVER                            0\n",
       "HOUSE                               0\n",
       "HANDSET_PRICE                       0\n",
       "OVER_15MINS_CALLS_PER_MONTH         0\n",
       "REPORTED_USAGE_LEVEL_high           0\n",
       "REPORTED_USAGE_LEVEL_little         0\n",
       "REPORTED_USAGE_LEVEL_very_high      0\n",
       "REPORTED_USAGE_LEVEL_very_little    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN 제거\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed = imputer.fit_transform(x)\n",
    "x = pd.DataFrame(imputed, columns=x.columns)\n",
    "x.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ce2de",
   "metadata": {},
   "source": [
    "데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9094f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=3000, random_state = 2022)\n",
    "# test는 마지막에 검사용으로 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdce4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=3000, random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b35be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "col_x = list(x)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_train_s = scaler.fit_transform(x_train)\n",
    "x_val_s = scaler.transform(x_val)\n",
    "x_test_s = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3c77755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfba5d8",
   "metadata": {},
   "source": [
    " 머신러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a730baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64      1520\n",
      "           1       0.63      0.62      0.63      1480\n",
      "\n",
      "    accuracy                           0.64      3000\n",
      "   macro avg       0.64      0.64      0.64      3000\n",
      "weighted avg       0.64      0.64      0.64      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(x_train, y_train)\n",
    "y_pred = model_lr.predict(x_val)\n",
    "print(classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54c72acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "\n",
    "model_dt = DecisionTreeClassifier()\n",
    "\n",
    "param = {'max_depth': range(1,101)}\n",
    "\n",
    "model_dt = GridSearchCV(model_dt, param, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34226a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 5}, 0.69975, DecisionTreeClassifier(max_depth=5))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt.fit(x_train,y_train)\n",
    "model_dt.best_params_, model_dt.best_score_,model_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0d89c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72      1520\n",
      "           1       0.71      0.70      0.70      1480\n",
      "\n",
      "    accuracy                           0.71      3000\n",
      "   macro avg       0.71      0.71      0.71      3000\n",
      "weighted avg       0.71      0.71      0.71      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dt.predict(x_val)\n",
    "print(classification_report(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3b1b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,15))\n",
    "# plt.barh(y=list(x), width=model_dt.best_estimator_.feature_importances_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4714c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20f192fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_knn = KNeighborsClassifier()\n",
    "params = {'n_neighbors':range(3,20)}\n",
    "m_knn_gs = GridSearchCV(m_knn, param_grid = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a65ab59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 19}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_knn_gs.fit(x_train, y_train)\n",
    "m_knn_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79f5e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.57      1520\n",
      "           1       0.58      0.71      0.64      1480\n",
      "\n",
      "    accuracy                           0.61      3000\n",
      "   macro avg       0.61      0.61      0.60      3000\n",
      "weighted avg       0.61      0.61      0.60      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_pred_knn = m_knn_gs.predict(x_val)\n",
    "print(classification_report(y_val, val_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79683f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
    "\n",
    "# param = {\n",
    "#     'max_depth':range(1, 21),\n",
    "#     'learning_rate':[0.01,0.1,0.2],\n",
    "#     'n_estimators':[20,201,10]\n",
    "# }\n",
    "\n",
    "# model_xgb = RandomizedSearchCV(model,\n",
    "#                               param,\n",
    "#                               cv=10,\n",
    "#                               n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3ad53f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68c20c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_xgb.predict(x_val)\n",
    "# print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f061c3",
   "metadata": {},
   "source": [
    "딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4eb4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4caa14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 16\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                  min_delta=0,\n",
    "                  patience=30,\n",
    "                  verbose=1,\n",
    "                  restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "382b0a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03eb89ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "il = Input(shape=(10,))\n",
    "ol = Dense(1, activation='sigmoid')(il)\n",
    "\n",
    "model_dl_1 = Model(il, ol)\n",
    "\n",
    "model_dl_1.compile(loss=binary_crossentropy,\n",
    "             optimizer=Adam(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model_dl_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5240deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7123 - accuracy: 0.5337 - val_loss: 0.6863 - val_accuracy: 0.5562\n",
      "Epoch 2/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6769 - accuracy: 0.5840 - val_loss: 0.6677 - val_accuracy: 0.6083\n",
      "Epoch 3/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6606 - accuracy: 0.6165 - val_loss: 0.6563 - val_accuracy: 0.6279\n",
      "Epoch 4/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6504 - accuracy: 0.6235 - val_loss: 0.6500 - val_accuracy: 0.6308\n",
      "Epoch 5/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6439 - accuracy: 0.6295 - val_loss: 0.6463 - val_accuracy: 0.6292\n",
      "Epoch 6/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6397 - accuracy: 0.6310 - val_loss: 0.6441 - val_accuracy: 0.6292\n",
      "Epoch 7/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6370 - accuracy: 0.6323 - val_loss: 0.6430 - val_accuracy: 0.6288\n",
      "Epoch 8/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6353 - accuracy: 0.6341 - val_loss: 0.6424 - val_accuracy: 0.6296\n",
      "Epoch 9/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6341 - accuracy: 0.6351 - val_loss: 0.6422 - val_accuracy: 0.6292\n",
      "Epoch 10/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6333 - accuracy: 0.6365 - val_loss: 0.6422 - val_accuracy: 0.6258\n",
      "Epoch 11/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6328 - accuracy: 0.6367 - val_loss: 0.6424 - val_accuracy: 0.6263\n",
      "Epoch 12/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6324 - accuracy: 0.6382 - val_loss: 0.6423 - val_accuracy: 0.6283\n",
      "Epoch 13/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6323 - accuracy: 0.6395 - val_loss: 0.6424 - val_accuracy: 0.6258\n",
      "Epoch 14/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6321 - accuracy: 0.6403 - val_loss: 0.6431 - val_accuracy: 0.6221\n",
      "Epoch 15/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6320 - accuracy: 0.6386 - val_loss: 0.6428 - val_accuracy: 0.6233\n",
      "Epoch 16/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6320 - accuracy: 0.6402 - val_loss: 0.6428 - val_accuracy: 0.6225\n",
      "Epoch 17/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6318 - accuracy: 0.6396 - val_loss: 0.6430 - val_accuracy: 0.6237\n",
      "Epoch 18/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6317 - accuracy: 0.6405 - val_loss: 0.6430 - val_accuracy: 0.6233\n",
      "Epoch 19/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6317 - accuracy: 0.6417 - val_loss: 0.6430 - val_accuracy: 0.6242\n",
      "Epoch 20/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6316 - accuracy: 0.6409 - val_loss: 0.6433 - val_accuracy: 0.6221\n",
      "Epoch 21/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6317 - accuracy: 0.6415 - val_loss: 0.6431 - val_accuracy: 0.6237\n",
      "Epoch 22/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6316 - accuracy: 0.6414 - val_loss: 0.6431 - val_accuracy: 0.6237\n",
      "Epoch 23/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6316 - accuracy: 0.6413 - val_loss: 0.6430 - val_accuracy: 0.6225\n",
      "Epoch 24/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6410 - val_loss: 0.6430 - val_accuracy: 0.6283\n",
      "Epoch 25/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6428 - val_loss: 0.6435 - val_accuracy: 0.6217\n",
      "Epoch 26/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6316 - accuracy: 0.6391 - val_loss: 0.6432 - val_accuracy: 0.6217\n",
      "Epoch 27/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6421 - val_loss: 0.6436 - val_accuracy: 0.6208\n",
      "Epoch 28/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6396 - val_loss: 0.6431 - val_accuracy: 0.6233\n",
      "Epoch 29/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6316 - accuracy: 0.6417 - val_loss: 0.6433 - val_accuracy: 0.6208\n",
      "Epoch 30/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6414 - val_loss: 0.6431 - val_accuracy: 0.6229\n",
      "Epoch 31/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6417 - val_loss: 0.6430 - val_accuracy: 0.6233\n",
      "Epoch 32/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6440 - val_loss: 0.6432 - val_accuracy: 0.6212\n",
      "Epoch 33/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6417 - val_loss: 0.6432 - val_accuracy: 0.6204\n",
      "Epoch 34/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6416 - val_loss: 0.6432 - val_accuracy: 0.6200\n",
      "Epoch 35/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6424 - val_loss: 0.6430 - val_accuracy: 0.6225\n",
      "Epoch 36/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6314 - accuracy: 0.6427 - val_loss: 0.6430 - val_accuracy: 0.6233\n",
      "Epoch 37/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6418 - val_loss: 0.6433 - val_accuracy: 0.6217\n",
      "Epoch 38/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6315 - accuracy: 0.6404 - val_loss: 0.6433 - val_accuracy: 0.6217\n",
      "Epoch 39/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6314 - accuracy: 0.6444 - val_loss: 0.6436 - val_accuracy: 0.6196\n",
      "Epoch 40/1000\n",
      "586/600 [============================>.] - ETA: 0s - loss: 0.6313 - accuracy: 0.6415Restoring model weights from the end of the best epoch: 10.\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6314 - accuracy: 0.6410 - val_loss: 0.6429 - val_accuracy: 0.6242\n",
      "Epoch 40: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc89be6f10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dl_1.fit(x_train_s, y_train,\n",
    "              epochs=epochs, batch_size=batch_size,\n",
    "              validation_split=0.2, verbose=1,\n",
    "              callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6070475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2816      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,377\n",
      "Trainable params: 21,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "il = Input(shape=(10,))\n",
    "h = Dense(256, activation='relu')(il)\n",
    "h = Dense(64, activation='relu')(h)\n",
    "h = Dense(32, activation='relu')(h)\n",
    "ol = Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "model_dl_2 = Model(il, ol)\n",
    "\n",
    "model_dl_2.compile(loss=binary_crossentropy,\n",
    "             optimizer=Adam(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model_dl_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b129235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "600/600 [==============================] - 2s 2ms/step - loss: 0.6292 - accuracy: 0.6464 - val_loss: 0.6455 - val_accuracy: 0.6471\n",
      "Epoch 2/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6166 - accuracy: 0.6601 - val_loss: 0.6277 - val_accuracy: 0.6517\n",
      "Epoch 3/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6107 - accuracy: 0.6684 - val_loss: 0.6258 - val_accuracy: 0.6583\n",
      "Epoch 4/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6082 - accuracy: 0.6746 - val_loss: 0.6131 - val_accuracy: 0.6725\n",
      "Epoch 5/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6034 - accuracy: 0.6774 - val_loss: 0.6213 - val_accuracy: 0.6683\n",
      "Epoch 6/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6016 - accuracy: 0.6758 - val_loss: 0.6099 - val_accuracy: 0.6754\n",
      "Epoch 7/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5947 - accuracy: 0.6861 - val_loss: 0.6111 - val_accuracy: 0.6692\n",
      "Epoch 8/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6874 - val_loss: 0.6007 - val_accuracy: 0.6792\n",
      "Epoch 9/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5871 - accuracy: 0.6913 - val_loss: 0.6122 - val_accuracy: 0.6708\n",
      "Epoch 10/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5862 - accuracy: 0.6886 - val_loss: 0.6060 - val_accuracy: 0.6746\n",
      "Epoch 11/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5828 - accuracy: 0.6928 - val_loss: 0.6056 - val_accuracy: 0.6775\n",
      "Epoch 12/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5812 - accuracy: 0.6963 - val_loss: 0.5960 - val_accuracy: 0.6850\n",
      "Epoch 13/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5788 - accuracy: 0.6994 - val_loss: 0.5975 - val_accuracy: 0.6771\n",
      "Epoch 14/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5770 - accuracy: 0.6974 - val_loss: 0.6036 - val_accuracy: 0.6787\n",
      "Epoch 15/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5762 - accuracy: 0.6965 - val_loss: 0.5907 - val_accuracy: 0.6800\n",
      "Epoch 16/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5749 - accuracy: 0.6969 - val_loss: 0.5909 - val_accuracy: 0.6812\n",
      "Epoch 17/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.7057 - val_loss: 0.5948 - val_accuracy: 0.6825\n",
      "Epoch 18/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.6998 - val_loss: 0.5996 - val_accuracy: 0.6846\n",
      "Epoch 19/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5710 - accuracy: 0.7058 - val_loss: 0.5910 - val_accuracy: 0.6825\n",
      "Epoch 20/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5701 - accuracy: 0.7022 - val_loss: 0.6022 - val_accuracy: 0.6742\n",
      "Epoch 21/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7094 - val_loss: 0.5895 - val_accuracy: 0.6862\n",
      "Epoch 22/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7072 - val_loss: 0.5989 - val_accuracy: 0.6783\n",
      "Epoch 23/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7066 - val_loss: 0.5928 - val_accuracy: 0.6908\n",
      "Epoch 24/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7124 - val_loss: 0.5996 - val_accuracy: 0.6817\n",
      "Epoch 25/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7111 - val_loss: 0.5939 - val_accuracy: 0.6846\n",
      "Epoch 26/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5615 - accuracy: 0.7091 - val_loss: 0.5987 - val_accuracy: 0.6837\n",
      "Epoch 27/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7118 - val_loss: 0.5982 - val_accuracy: 0.6854\n",
      "Epoch 28/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5586 - accuracy: 0.7114 - val_loss: 0.6009 - val_accuracy: 0.6808\n",
      "Epoch 29/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5568 - accuracy: 0.7147 - val_loss: 0.5970 - val_accuracy: 0.6846\n",
      "Epoch 30/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5552 - accuracy: 0.7173 - val_loss: 0.6072 - val_accuracy: 0.6783\n",
      "Epoch 31/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7155 - val_loss: 0.5976 - val_accuracy: 0.6829\n",
      "Epoch 32/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5534 - accuracy: 0.7124 - val_loss: 0.6058 - val_accuracy: 0.6812\n",
      "Epoch 33/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7201 - val_loss: 0.6041 - val_accuracy: 0.6792\n",
      "Epoch 34/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7214 - val_loss: 0.5991 - val_accuracy: 0.6888\n",
      "Epoch 35/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5493 - accuracy: 0.7205 - val_loss: 0.6092 - val_accuracy: 0.6833\n",
      "Epoch 36/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5478 - accuracy: 0.7218 - val_loss: 0.6084 - val_accuracy: 0.6775\n",
      "Epoch 37/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7242 - val_loss: 0.6128 - val_accuracy: 0.6879\n",
      "Epoch 38/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7233 - val_loss: 0.6168 - val_accuracy: 0.6817\n",
      "Epoch 39/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7267 - val_loss: 0.6035 - val_accuracy: 0.6908\n",
      "Epoch 40/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7265 - val_loss: 0.6163 - val_accuracy: 0.6754\n",
      "Epoch 41/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7267 - val_loss: 0.6074 - val_accuracy: 0.6871\n",
      "Epoch 42/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7275 - val_loss: 0.6091 - val_accuracy: 0.6837\n",
      "Epoch 43/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7266 - val_loss: 0.6138 - val_accuracy: 0.6808\n",
      "Epoch 44/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7296 - val_loss: 0.6157 - val_accuracy: 0.6817\n",
      "Epoch 45/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7319 - val_loss: 0.6213 - val_accuracy: 0.6900\n",
      "Epoch 46/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7349 - val_loss: 0.6161 - val_accuracy: 0.6846\n",
      "Epoch 47/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7317 - val_loss: 0.6202 - val_accuracy: 0.6808\n",
      "Epoch 48/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5250 - accuracy: 0.7372 - val_loss: 0.6267 - val_accuracy: 0.6750\n",
      "Epoch 49/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5235 - accuracy: 0.7376 - val_loss: 0.6298 - val_accuracy: 0.6837\n",
      "Epoch 50/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.7389 - val_loss: 0.6305 - val_accuracy: 0.6733\n",
      "Epoch 51/1000\n",
      "598/600 [============================>.] - ETA: 0s - loss: 0.5187 - accuracy: 0.7376Restoring model weights from the end of the best epoch: 21.\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7375 - val_loss: 0.6346 - val_accuracy: 0.6808\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc8affefa0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dl_2.fit(x_train_s, y_train,\n",
    "              epochs=epochs, batch_size=batch_size,\n",
    "              validation_split=0.2, verbose=1,\n",
    "              callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0e88586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                352       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "il = Input(shape=(10,))\n",
    "h = Dense(32, activation='relu')(il)\n",
    "ol = Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "model_dl_3 = Model(il, ol)\n",
    "\n",
    "model_dl_3.compile(loss=binary_crossentropy,\n",
    "             optimizer=Adam(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model_dl_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46351b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6601 - accuracy: 0.6069 - val_loss: 0.6415 - val_accuracy: 0.6242\n",
      "Epoch 2/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6318 - accuracy: 0.6460 - val_loss: 0.6412 - val_accuracy: 0.6396\n",
      "Epoch 3/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6285 - accuracy: 0.6483 - val_loss: 0.6351 - val_accuracy: 0.6338\n",
      "Epoch 4/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.6544 - val_loss: 0.6358 - val_accuracy: 0.6304\n",
      "Epoch 5/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6223 - accuracy: 0.6604 - val_loss: 0.6315 - val_accuracy: 0.6438\n",
      "Epoch 6/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6205 - accuracy: 0.6609 - val_loss: 0.6278 - val_accuracy: 0.6504\n",
      "Epoch 7/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6182 - accuracy: 0.6603 - val_loss: 0.6247 - val_accuracy: 0.6521\n",
      "Epoch 8/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6162 - accuracy: 0.6604 - val_loss: 0.6237 - val_accuracy: 0.6592\n",
      "Epoch 9/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6151 - accuracy: 0.6644 - val_loss: 0.6255 - val_accuracy: 0.6558\n",
      "Epoch 10/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6131 - accuracy: 0.6642 - val_loss: 0.6230 - val_accuracy: 0.6596\n",
      "Epoch 11/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6126 - accuracy: 0.6662 - val_loss: 0.6182 - val_accuracy: 0.6629\n",
      "Epoch 12/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6109 - accuracy: 0.6686 - val_loss: 0.6211 - val_accuracy: 0.6592\n",
      "Epoch 13/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6096 - accuracy: 0.6672 - val_loss: 0.6231 - val_accuracy: 0.6525\n",
      "Epoch 14/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6090 - accuracy: 0.6667 - val_loss: 0.6204 - val_accuracy: 0.6567\n",
      "Epoch 15/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6081 - accuracy: 0.6699 - val_loss: 0.6154 - val_accuracy: 0.6700\n",
      "Epoch 16/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6066 - accuracy: 0.6737 - val_loss: 0.6157 - val_accuracy: 0.6608\n",
      "Epoch 17/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6064 - accuracy: 0.6703 - val_loss: 0.6140 - val_accuracy: 0.6737\n",
      "Epoch 18/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6055 - accuracy: 0.6712 - val_loss: 0.6148 - val_accuracy: 0.6717\n",
      "Epoch 19/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6050 - accuracy: 0.6707 - val_loss: 0.6190 - val_accuracy: 0.6729\n",
      "Epoch 20/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6044 - accuracy: 0.6686 - val_loss: 0.6159 - val_accuracy: 0.6696\n",
      "Epoch 21/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.6719 - val_loss: 0.6133 - val_accuracy: 0.6679\n",
      "Epoch 22/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6033 - accuracy: 0.6726 - val_loss: 0.6099 - val_accuracy: 0.6717\n",
      "Epoch 23/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6024 - accuracy: 0.6768 - val_loss: 0.6116 - val_accuracy: 0.6700\n",
      "Epoch 24/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6012 - accuracy: 0.6795 - val_loss: 0.6134 - val_accuracy: 0.6796\n",
      "Epoch 25/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6012 - accuracy: 0.6755 - val_loss: 0.6123 - val_accuracy: 0.6637\n",
      "Epoch 26/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6006 - accuracy: 0.6755 - val_loss: 0.6119 - val_accuracy: 0.6787\n",
      "Epoch 27/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6010 - accuracy: 0.6772 - val_loss: 0.6088 - val_accuracy: 0.6708\n",
      "Epoch 28/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5994 - accuracy: 0.6756 - val_loss: 0.6099 - val_accuracy: 0.6662\n",
      "Epoch 29/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5992 - accuracy: 0.6775 - val_loss: 0.6080 - val_accuracy: 0.6775\n",
      "Epoch 30/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5986 - accuracy: 0.6764 - val_loss: 0.6085 - val_accuracy: 0.6800\n",
      "Epoch 31/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5988 - accuracy: 0.6805 - val_loss: 0.6074 - val_accuracy: 0.6808\n",
      "Epoch 32/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5977 - accuracy: 0.6809 - val_loss: 0.6053 - val_accuracy: 0.6733\n",
      "Epoch 33/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5975 - accuracy: 0.6797 - val_loss: 0.6094 - val_accuracy: 0.6808\n",
      "Epoch 34/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5970 - accuracy: 0.6805 - val_loss: 0.6096 - val_accuracy: 0.6754\n",
      "Epoch 35/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5967 - accuracy: 0.6781 - val_loss: 0.6065 - val_accuracy: 0.6779\n",
      "Epoch 36/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5962 - accuracy: 0.6812 - val_loss: 0.6078 - val_accuracy: 0.6854\n",
      "Epoch 37/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5958 - accuracy: 0.6804 - val_loss: 0.6054 - val_accuracy: 0.6833\n",
      "Epoch 38/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5954 - accuracy: 0.6790 - val_loss: 0.6055 - val_accuracy: 0.6846\n",
      "Epoch 39/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5951 - accuracy: 0.6819 - val_loss: 0.6046 - val_accuracy: 0.6733\n",
      "Epoch 40/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5947 - accuracy: 0.6834 - val_loss: 0.6049 - val_accuracy: 0.6829\n",
      "Epoch 41/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5938 - accuracy: 0.6790 - val_loss: 0.6141 - val_accuracy: 0.6750\n",
      "Epoch 42/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5937 - accuracy: 0.6811 - val_loss: 0.6036 - val_accuracy: 0.6808\n",
      "Epoch 43/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5941 - accuracy: 0.6802 - val_loss: 0.6027 - val_accuracy: 0.6800\n",
      "Epoch 44/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5938 - accuracy: 0.6794 - val_loss: 0.6014 - val_accuracy: 0.6842\n",
      "Epoch 45/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5929 - accuracy: 0.6791 - val_loss: 0.6039 - val_accuracy: 0.6771\n",
      "Epoch 46/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5924 - accuracy: 0.6814 - val_loss: 0.6017 - val_accuracy: 0.6850\n",
      "Epoch 47/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5920 - accuracy: 0.6808 - val_loss: 0.6047 - val_accuracy: 0.6767\n",
      "Epoch 48/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5920 - accuracy: 0.6825 - val_loss: 0.6040 - val_accuracy: 0.6754\n",
      "Epoch 49/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5919 - accuracy: 0.6812 - val_loss: 0.6074 - val_accuracy: 0.6842\n",
      "Epoch 50/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5912 - accuracy: 0.6843 - val_loss: 0.6044 - val_accuracy: 0.6817\n",
      "Epoch 51/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5913 - accuracy: 0.6808 - val_loss: 0.6040 - val_accuracy: 0.6829\n",
      "Epoch 52/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5906 - accuracy: 0.6845 - val_loss: 0.6032 - val_accuracy: 0.6808\n",
      "Epoch 53/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5912 - accuracy: 0.6822 - val_loss: 0.6022 - val_accuracy: 0.6858\n",
      "Epoch 54/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5902 - accuracy: 0.6829 - val_loss: 0.6000 - val_accuracy: 0.6846\n",
      "Epoch 55/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5910 - accuracy: 0.6824 - val_loss: 0.6014 - val_accuracy: 0.6837\n",
      "Epoch 56/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5905 - accuracy: 0.6830 - val_loss: 0.6016 - val_accuracy: 0.6792\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6849 - val_loss: 0.6047 - val_accuracy: 0.6837\n",
      "Epoch 58/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5893 - accuracy: 0.6825 - val_loss: 0.6002 - val_accuracy: 0.6808\n",
      "Epoch 59/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5898 - accuracy: 0.6829 - val_loss: 0.6013 - val_accuracy: 0.6850\n",
      "Epoch 60/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5888 - accuracy: 0.6822 - val_loss: 0.6036 - val_accuracy: 0.6779\n",
      "Epoch 61/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6843 - val_loss: 0.6042 - val_accuracy: 0.6762\n",
      "Epoch 62/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.6832 - val_loss: 0.6003 - val_accuracy: 0.6842\n",
      "Epoch 63/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5884 - accuracy: 0.6837 - val_loss: 0.6022 - val_accuracy: 0.6779\n",
      "Epoch 64/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5886 - accuracy: 0.6873 - val_loss: 0.6014 - val_accuracy: 0.6783\n",
      "Epoch 65/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.6841 - val_loss: 0.6015 - val_accuracy: 0.6842\n",
      "Epoch 66/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.6845 - val_loss: 0.6033 - val_accuracy: 0.6821\n",
      "Epoch 67/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.6851 - val_loss: 0.6013 - val_accuracy: 0.6871\n",
      "Epoch 68/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5876 - accuracy: 0.6852 - val_loss: 0.6038 - val_accuracy: 0.6913\n",
      "Epoch 69/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5879 - accuracy: 0.6853 - val_loss: 0.5997 - val_accuracy: 0.6837\n",
      "Epoch 70/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5875 - accuracy: 0.6821 - val_loss: 0.5994 - val_accuracy: 0.6842\n",
      "Epoch 71/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5875 - accuracy: 0.6855 - val_loss: 0.6010 - val_accuracy: 0.6908\n",
      "Epoch 72/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5871 - accuracy: 0.6842 - val_loss: 0.6021 - val_accuracy: 0.6775\n",
      "Epoch 73/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5866 - accuracy: 0.6849 - val_loss: 0.5998 - val_accuracy: 0.6883\n",
      "Epoch 74/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5864 - accuracy: 0.6871 - val_loss: 0.5993 - val_accuracy: 0.6871\n",
      "Epoch 75/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5856 - accuracy: 0.6871 - val_loss: 0.6037 - val_accuracy: 0.6775\n",
      "Epoch 76/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5860 - accuracy: 0.6866 - val_loss: 0.6005 - val_accuracy: 0.6842\n",
      "Epoch 77/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5860 - accuracy: 0.6889 - val_loss: 0.6035 - val_accuracy: 0.6737\n",
      "Epoch 78/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5850 - accuracy: 0.6889 - val_loss: 0.6008 - val_accuracy: 0.6900\n",
      "Epoch 79/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5857 - accuracy: 0.6833 - val_loss: 0.5999 - val_accuracy: 0.6896\n",
      "Epoch 80/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5860 - accuracy: 0.6837 - val_loss: 0.6026 - val_accuracy: 0.6871\n",
      "Epoch 81/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5852 - accuracy: 0.6870 - val_loss: 0.5988 - val_accuracy: 0.6908\n",
      "Epoch 82/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5856 - accuracy: 0.6853 - val_loss: 0.6008 - val_accuracy: 0.6837\n",
      "Epoch 83/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5854 - accuracy: 0.6872 - val_loss: 0.6046 - val_accuracy: 0.6892\n",
      "Epoch 84/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5848 - accuracy: 0.6865 - val_loss: 0.6028 - val_accuracy: 0.6771\n",
      "Epoch 85/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5851 - accuracy: 0.6874 - val_loss: 0.6073 - val_accuracy: 0.6812\n",
      "Epoch 86/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5849 - accuracy: 0.6873 - val_loss: 0.6035 - val_accuracy: 0.6875\n",
      "Epoch 87/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5854 - accuracy: 0.6875 - val_loss: 0.5987 - val_accuracy: 0.6921\n",
      "Epoch 88/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5846 - accuracy: 0.6839 - val_loss: 0.6021 - val_accuracy: 0.6854\n",
      "Epoch 89/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5839 - accuracy: 0.6871 - val_loss: 0.6009 - val_accuracy: 0.6775\n",
      "Epoch 90/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5848 - accuracy: 0.6859 - val_loss: 0.6009 - val_accuracy: 0.6850\n",
      "Epoch 91/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5844 - accuracy: 0.6856 - val_loss: 0.6007 - val_accuracy: 0.6854\n",
      "Epoch 92/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5844 - accuracy: 0.6859 - val_loss: 0.5982 - val_accuracy: 0.6904\n",
      "Epoch 93/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5840 - accuracy: 0.6897 - val_loss: 0.6031 - val_accuracy: 0.6842\n",
      "Epoch 94/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5836 - accuracy: 0.6837 - val_loss: 0.5998 - val_accuracy: 0.6858\n",
      "Epoch 95/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5832 - accuracy: 0.6893 - val_loss: 0.6036 - val_accuracy: 0.6821\n",
      "Epoch 96/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5836 - accuracy: 0.6875 - val_loss: 0.6023 - val_accuracy: 0.6858\n",
      "Epoch 97/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5836 - accuracy: 0.6875 - val_loss: 0.6006 - val_accuracy: 0.6858\n",
      "Epoch 98/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5837 - accuracy: 0.6899 - val_loss: 0.6041 - val_accuracy: 0.6850\n",
      "Epoch 99/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5836 - accuracy: 0.6861 - val_loss: 0.6002 - val_accuracy: 0.6854\n",
      "Epoch 100/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5827 - accuracy: 0.6880 - val_loss: 0.6002 - val_accuracy: 0.6900\n",
      "Epoch 101/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5834 - accuracy: 0.6853 - val_loss: 0.5999 - val_accuracy: 0.6837\n",
      "Epoch 102/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5828 - accuracy: 0.6902 - val_loss: 0.5997 - val_accuracy: 0.6875\n",
      "Epoch 103/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5828 - accuracy: 0.6903 - val_loss: 0.5998 - val_accuracy: 0.6862\n",
      "Epoch 104/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5830 - accuracy: 0.6890 - val_loss: 0.5980 - val_accuracy: 0.6913\n",
      "Epoch 105/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5827 - accuracy: 0.6902 - val_loss: 0.6014 - val_accuracy: 0.6883\n",
      "Epoch 106/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5830 - accuracy: 0.6881 - val_loss: 0.5989 - val_accuracy: 0.6908\n",
      "Epoch 107/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5824 - accuracy: 0.6870 - val_loss: 0.6023 - val_accuracy: 0.6842\n",
      "Epoch 108/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5830 - accuracy: 0.6890 - val_loss: 0.5991 - val_accuracy: 0.6900\n",
      "Epoch 109/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5822 - accuracy: 0.6867 - val_loss: 0.6021 - val_accuracy: 0.6883\n",
      "Epoch 110/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5822 - accuracy: 0.6883 - val_loss: 0.6018 - val_accuracy: 0.6858\n",
      "Epoch 111/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5820 - accuracy: 0.6876 - val_loss: 0.6000 - val_accuracy: 0.6871\n",
      "Epoch 112/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5824 - accuracy: 0.6858 - val_loss: 0.6007 - val_accuracy: 0.6904\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5824 - accuracy: 0.6877 - val_loss: 0.6007 - val_accuracy: 0.6888\n",
      "Epoch 114/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5823 - accuracy: 0.6864 - val_loss: 0.5994 - val_accuracy: 0.6888\n",
      "Epoch 115/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5818 - accuracy: 0.6880 - val_loss: 0.6013 - val_accuracy: 0.6842\n",
      "Epoch 116/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5816 - accuracy: 0.6877 - val_loss: 0.6011 - val_accuracy: 0.6908\n",
      "Epoch 117/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5819 - accuracy: 0.6894 - val_loss: 0.6010 - val_accuracy: 0.6900\n",
      "Epoch 118/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5818 - accuracy: 0.6928 - val_loss: 0.6019 - val_accuracy: 0.6821\n",
      "Epoch 119/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5816 - accuracy: 0.6879 - val_loss: 0.6001 - val_accuracy: 0.6825\n",
      "Epoch 120/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5818 - accuracy: 0.6865 - val_loss: 0.6007 - val_accuracy: 0.6858\n",
      "Epoch 121/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5816 - accuracy: 0.6896 - val_loss: 0.6015 - val_accuracy: 0.6875\n",
      "Epoch 122/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5813 - accuracy: 0.6879 - val_loss: 0.6032 - val_accuracy: 0.6879\n",
      "Epoch 123/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5809 - accuracy: 0.6902 - val_loss: 0.6007 - val_accuracy: 0.6858\n",
      "Epoch 124/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5808 - accuracy: 0.6891 - val_loss: 0.5999 - val_accuracy: 0.6921\n",
      "Epoch 125/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5808 - accuracy: 0.6885 - val_loss: 0.6009 - val_accuracy: 0.6867\n",
      "Epoch 126/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5805 - accuracy: 0.6888 - val_loss: 0.6024 - val_accuracy: 0.6929\n",
      "Epoch 127/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.5810 - accuracy: 0.6936 - val_loss: 0.6004 - val_accuracy: 0.6833\n",
      "Epoch 128/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.6879 - val_loss: 0.6008 - val_accuracy: 0.6862\n",
      "Epoch 129/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.6892 - val_loss: 0.6017 - val_accuracy: 0.6829\n",
      "Epoch 130/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.6902 - val_loss: 0.6032 - val_accuracy: 0.6854\n",
      "Epoch 131/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5811 - accuracy: 0.6869 - val_loss: 0.5992 - val_accuracy: 0.6854\n",
      "Epoch 132/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5805 - accuracy: 0.6894 - val_loss: 0.6034 - val_accuracy: 0.6833\n",
      "Epoch 133/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.6905 - val_loss: 0.5982 - val_accuracy: 0.6896\n",
      "Epoch 134/1000\n",
      "566/600 [===========================>..] - ETA: 0s - loss: 0.5809 - accuracy: 0.6881Restoring model weights from the end of the best epoch: 104.\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5803 - accuracy: 0.6885 - val_loss: 0.5997 - val_accuracy: 0.6917\n",
      "Epoch 134: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc8d234d30>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dl_3.fit(x_train_s, y_train,\n",
    "              epochs=epochs, batch_size=batch_size,\n",
    "              validation_split=0.2, verbose=1,\n",
    "              callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b00f70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               5632      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,225\n",
      "Trainable params: 180,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "il = Input(shape=(10,))\n",
    "h = Dense(512, activation='relu')(il)\n",
    "h = Dense(256, activation='relu')(h)\n",
    "h = Dense(128, activation='relu')(h)\n",
    "h = Dense(64, activation='relu')(h)\n",
    "h = Dense(32, activation='relu')(h)\n",
    "ol = Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "model_dl_4 = Model(il, ol)\n",
    "\n",
    "model_dl_4.compile(loss=binary_crossentropy,\n",
    "             optimizer=Adam(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model_dl_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ffdaf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.6341 - accuracy: 0.6416 - val_loss: 0.6240 - val_accuracy: 0.6596\n",
      "Epoch 2/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6171 - accuracy: 0.6667 - val_loss: 0.6218 - val_accuracy: 0.6650\n",
      "Epoch 3/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6143 - accuracy: 0.6695 - val_loss: 0.6158 - val_accuracy: 0.6696\n",
      "Epoch 4/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6081 - accuracy: 0.6761 - val_loss: 0.6111 - val_accuracy: 0.6729\n",
      "Epoch 5/1000\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.6028 - accuracy: 0.6782 - val_loss: 0.6144 - val_accuracy: 0.6779\n",
      "Epoch 6/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5994 - accuracy: 0.6794 - val_loss: 0.6001 - val_accuracy: 0.6833\n",
      "Epoch 7/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.6857 - val_loss: 0.6028 - val_accuracy: 0.6725\n",
      "Epoch 8/1000\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5897 - accuracy: 0.6864 - val_loss: 0.6063 - val_accuracy: 0.6717\n",
      "Epoch 9/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5860 - accuracy: 0.6913 - val_loss: 0.5976 - val_accuracy: 0.6725\n",
      "Epoch 10/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5839 - accuracy: 0.6955 - val_loss: 0.5957 - val_accuracy: 0.6896\n",
      "Epoch 11/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5820 - accuracy: 0.6981 - val_loss: 0.6025 - val_accuracy: 0.6817\n",
      "Epoch 12/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5803 - accuracy: 0.6956 - val_loss: 0.5981 - val_accuracy: 0.6854\n",
      "Epoch 13/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5805 - accuracy: 0.6960 - val_loss: 0.6005 - val_accuracy: 0.6817\n",
      "Epoch 14/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5767 - accuracy: 0.6983 - val_loss: 0.5917 - val_accuracy: 0.6837\n",
      "Epoch 15/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5773 - accuracy: 0.7008 - val_loss: 0.5926 - val_accuracy: 0.6908\n",
      "Epoch 16/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.6994 - val_loss: 0.5920 - val_accuracy: 0.6892\n",
      "Epoch 17/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5739 - accuracy: 0.7011 - val_loss: 0.6002 - val_accuracy: 0.6825\n",
      "Epoch 18/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5694 - accuracy: 0.7078 - val_loss: 0.5974 - val_accuracy: 0.6850\n",
      "Epoch 19/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5708 - accuracy: 0.7050 - val_loss: 0.6008 - val_accuracy: 0.6913\n",
      "Epoch 20/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7085 - val_loss: 0.5999 - val_accuracy: 0.6808\n",
      "Epoch 21/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7120 - val_loss: 0.6068 - val_accuracy: 0.6850\n",
      "Epoch 22/1000\n",
      "600/600 [==============================] - 2s 2ms/step - loss: 0.5642 - accuracy: 0.7128 - val_loss: 0.5958 - val_accuracy: 0.6904\n",
      "Epoch 23/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7092 - val_loss: 0.5930 - val_accuracy: 0.6904\n",
      "Epoch 24/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7140 - val_loss: 0.6018 - val_accuracy: 0.6804\n",
      "Epoch 25/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5598 - accuracy: 0.7130 - val_loss: 0.6085 - val_accuracy: 0.6833\n",
      "Epoch 26/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5595 - accuracy: 0.7139 - val_loss: 0.6084 - val_accuracy: 0.6775\n",
      "Epoch 27/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5568 - accuracy: 0.7141 - val_loss: 0.6052 - val_accuracy: 0.6737\n",
      "Epoch 28/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5556 - accuracy: 0.7165 - val_loss: 0.5981 - val_accuracy: 0.6867\n",
      "Epoch 29/1000\n",
      "600/600 [==============================] - 2s 2ms/step - loss: 0.5545 - accuracy: 0.7178 - val_loss: 0.6034 - val_accuracy: 0.6833\n",
      "Epoch 30/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7164 - val_loss: 0.6032 - val_accuracy: 0.6779\n",
      "Epoch 31/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5510 - accuracy: 0.7172 - val_loss: 0.6119 - val_accuracy: 0.6833\n",
      "Epoch 32/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7229 - val_loss: 0.6204 - val_accuracy: 0.6750\n",
      "Epoch 33/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7216 - val_loss: 0.6129 - val_accuracy: 0.6817\n",
      "Epoch 34/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7233 - val_loss: 0.6187 - val_accuracy: 0.6837\n",
      "Epoch 35/1000\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5374 - accuracy: 0.7280 - val_loss: 0.6108 - val_accuracy: 0.6846\n",
      "Epoch 36/1000\n",
      "600/600 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7260 - val_loss: 0.6108 - val_accuracy: 0.6792\n",
      "Epoch 37/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7258 - val_loss: 0.6273 - val_accuracy: 0.6862\n",
      "Epoch 38/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5271 - accuracy: 0.7292 - val_loss: 0.6328 - val_accuracy: 0.6837\n",
      "Epoch 39/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5275 - accuracy: 0.7316 - val_loss: 0.6346 - val_accuracy: 0.6858\n",
      "Epoch 40/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.7311 - val_loss: 0.6538 - val_accuracy: 0.6783\n",
      "Epoch 41/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5193 - accuracy: 0.7353 - val_loss: 0.6458 - val_accuracy: 0.6775\n",
      "Epoch 42/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5135 - accuracy: 0.7397 - val_loss: 0.6495 - val_accuracy: 0.6817\n",
      "Epoch 43/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.7407 - val_loss: 0.6702 - val_accuracy: 0.6737\n",
      "Epoch 44/1000\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.7404Restoring model weights from the end of the best epoch: 14.\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5093 - accuracy: 0.7404 - val_loss: 0.6548 - val_accuracy: 0.6767\n",
      "Epoch 44: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc8d2768b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dl_4.fit(x_train_s, y_train,\n",
    "              epochs=epochs, batch_size=batch_size,\n",
    "              validation_split=0.2, verbose=1,\n",
    "              callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d80bd1c",
   "metadata": {},
   "source": [
    "# 성능 비교\n",
    "## 평가지표 : classification_reportd의 accuracy + 1의 f1-score\n",
    "\n",
    "###  - accuracy를 통해 정확도를 보고\n",
    "###  - 1의 f1-score를 통해 전체적인 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9eb2403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66      1520\n",
      "           1       0.65      0.62      0.64      1480\n",
      "\n",
      "    accuracy                           0.65      3000\n",
      "   macro avg       0.65      0.65      0.65      3000\n",
      "weighted avg       0.65      0.65      0.65      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dl_1.predict(x_val_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8299d5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      1520\n",
      "           1       0.70      0.66      0.68      1480\n",
      "\n",
      "    accuracy                           0.69      3000\n",
      "   macro avg       0.69      0.69      0.69      3000\n",
      "weighted avg       0.69      0.69      0.69      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dl_2.predict(x_val_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffba178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68      1520\n",
      "           1       0.67      0.70      0.69      1480\n",
      "\n",
      "    accuracy                           0.68      3000\n",
      "   macro avg       0.68      0.68      0.68      3000\n",
      "weighted avg       0.68      0.68      0.68      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dl_3.predict(x_val_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56d8fb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      1520\n",
      "           1       0.70      0.70      0.70      1480\n",
      "\n",
      "    accuracy                           0.70      3000\n",
      "   macro avg       0.70      0.70      0.70      3000\n",
      "weighted avg       0.70      0.70      0.70      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dl_4.predict(x_val_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64204ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64      1520\n",
      "           1       0.63      0.62      0.63      1480\n",
      "\n",
      "    accuracy                           0.64      3000\n",
      "   macro avg       0.64      0.64      0.64      3000\n",
      "weighted avg       0.64      0.64      0.64      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "result_f1={}\n",
    "result_acc={}\n",
    "\n",
    "y_pred = model_lr.predict(x_val)\n",
    "result_f1['Logistic Regression'] = f1_score(y_val, y_pred)\n",
    "result_acc['Logistic Regression'] = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5a23858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72      1520\n",
      "           1       0.71      0.70      0.70      1480\n",
      "\n",
      "    accuracy                           0.71      3000\n",
      "   macro avg       0.71      0.71      0.71      3000\n",
      "weighted avg       0.71      0.71      0.71      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dt.predict(x_val)\n",
    "result_f1['Decision Tree'] = f1_score(y_val, y_pred)\n",
    "result_acc['Decision Tree'] = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2b2a96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.57      1520\n",
      "           1       0.58      0.71      0.64      1480\n",
      "\n",
      "    accuracy                           0.61      3000\n",
      "   macro avg       0.61      0.61      0.60      3000\n",
      "weighted avg       0.61      0.61      0.60      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = m_knn_gs.predict(x_val)\n",
    "result_f1['KNeighbors'] = f1_score(y_val, y_pred)\n",
    "result_acc['KNeighbors'] = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b2e2357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66      1520\n",
      "           1       0.65      0.62      0.64      1480\n",
      "\n",
      "    accuracy                           0.65      3000\n",
      "   macro avg       0.65      0.65      0.65      3000\n",
      "weighted avg       0.65      0.65      0.65      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dl_1.predict(x_val_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "result_f1['DL 1'] = f1_score(y_val, y_pred)\n",
    "result_acc['DL 1'] = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ea39f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      1520\n",
      "           1       0.70      0.66      0.68      1480\n",
      "\n",
      "    accuracy                           0.69      3000\n",
      "   macro avg       0.69      0.69      0.69      3000\n",
      "weighted avg       0.69      0.69      0.69      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dl_2.predict(x_val_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "result_f1['DL 2'] = f1_score(y_val, y_pred)\n",
    "result_acc['DL 2'] = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41d4bbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68      1520\n",
      "           1       0.67      0.70      0.69      1480\n",
      "\n",
      "    accuracy                           0.68      3000\n",
      "   macro avg       0.68      0.68      0.68      3000\n",
      "weighted avg       0.68      0.68      0.68      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dl_3.predict(x_val_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "result_f1['DL 3'] = f1_score(y_val, y_pred)\n",
    "result_acc['DL 3'] = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5385d9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      1520\n",
      "           1       0.70      0.70      0.70      1480\n",
      "\n",
      "    accuracy                           0.70      3000\n",
      "   macro avg       0.70      0.70      0.70      3000\n",
      "weighted avg       0.70      0.70      0.70      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_dl_4.predict(x_val_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "result_f1['DL 4'] = f1_score(y_val, y_pred)\n",
    "result_acc['DL 4'] = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56f8e4f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Logistic Regression\n",
      "------------------------------\n",
      "Accuracy:  0.64 f1-score:  0.63\n",
      "==============================\n",
      "Decision Tree\n",
      "------------------------------\n",
      "Accuracy:  0.71 f1-score:  0.7\n",
      "==============================\n",
      "KNeighbors\n",
      "------------------------------\n",
      "Accuracy:  0.61 f1-score:  0.64\n",
      "==============================\n",
      "DL 1\n",
      "------------------------------\n",
      "Accuracy:  0.65 f1-score:  0.64\n",
      "==============================\n",
      "DL 2\n",
      "------------------------------\n",
      "Accuracy:  0.69 f1-score:  0.68\n",
      "==============================\n",
      "DL 3\n",
      "------------------------------\n",
      "Accuracy:  0.68 f1-score:  0.69\n",
      "==============================\n",
      "DL 4\n",
      "------------------------------\n",
      "Accuracy:  0.7 f1-score:  0.7\n"
     ]
    }
   ],
   "source": [
    "for (name, acc), (_, f1) in zip(result_acc.items(), result_f1.items()):\n",
    "    print('='*30)\n",
    "    print(name)\n",
    "    print('-'*30)\n",
    "    print('Accuracy: ', round(acc,2), 'f1-score: ', round(f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52f261",
   "metadata": {},
   "source": [
    "### accuracy와 f10-score 둘다 높은  Decision Tree , DL 4 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08d5b4",
   "metadata": {},
   "source": [
    "### 최종 성능 평가( Test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5d3284d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 10),\n",
       " (3000,),\n",
       " 0    1540\n",
       " 1    1460\n",
       " Name: CHURN, dtype: int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스케일링\n",
    "\n",
    "x_test_s = scaler.transform(x_test)\n",
    "x_test.shape, y_test.shape, y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aba31b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_f1_test = {}\n",
    "result_acc_test = {}\n",
    "\n",
    "y_pred = model_lr.predict(x_test)\n",
    "result_f1_test['Logistic Regression'] = f1_score(y_test, y_pred)\n",
    "result_acc_test['Logistic Regression'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred = model_dt.predict(x_test)\n",
    "result_f1_test['Decision Tree'] = f1_score(y_test, y_pred)\n",
    "result_acc_test['Decision Tree'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred = m_knn_gs.predict(x_test)\n",
    "result_f1_test['KNeighbors'] = f1_score(y_test, y_pred)\n",
    "result_acc_test['KNeighbors'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred = model_dl_1.predict(x_test_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "result_f1_test['DL 1'] = f1_score(y_test, y_pred)\n",
    "result_acc_test['DL 1'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred = model_dl_2.predict(x_test_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "result_f1_test['DL 2'] = f1_score(y_test, y_pred)\n",
    "result_acc_test['DL 2'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred = model_dl_3.predict(x_test_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "result_f1_test['DL 3'] = f1_score(y_test, y_pred)\n",
    "result_acc_test['DL 3'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred = model_dl_4.predict(x_test_s)\n",
    "y_pred = y_pred.round().reshape(-1)\n",
    "result_f1_test['DL 4'] = f1_score(y_test, y_pred)\n",
    "result_acc_test['DL 4'] = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "062d440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Logistic Regression\n",
      "------------------------------\n",
      "Accuracy:  0.62 f1-score:  0.61\n",
      "==============================\n",
      "Decision Tree\n",
      "------------------------------\n",
      "Accuracy:  0.68 f1-score:  0.67\n",
      "==============================\n",
      "KNeighbors\n",
      "------------------------------\n",
      "Accuracy:  0.61 f1-score:  0.64\n",
      "==============================\n",
      "DL 1\n",
      "------------------------------\n",
      "Accuracy:  0.63 f1-score:  0.61\n",
      "==============================\n",
      "DL 2\n",
      "------------------------------\n",
      "Accuracy:  0.67 f1-score:  0.66\n",
      "==============================\n",
      "DL 3\n",
      "------------------------------\n",
      "Accuracy:  0.67 f1-score:  0.67\n",
      "==============================\n",
      "DL 4\n",
      "------------------------------\n",
      "Accuracy:  0.68 f1-score:  0.67\n"
     ]
    }
   ],
   "source": [
    "for (name, acc), (_, f1) in zip(result_acc_test.items(), result_f1_test.items()):\n",
    "    print('='*30)\n",
    "    print(name)\n",
    "    print('-'*30)\n",
    "    print('Accuracy: ', round(acc,2), 'f1-score: ', round(f1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 예상했던 Decision Tree , DL 4 가 test set에 대하여 좋게 보인다.\n",
    " # 예상과 달리 test set에서의 DL 2, DL 3의 모델도 Decision Tree와 DL 4와 큰 차이는 없었다.\n",
    " # 새로운 feature 값을 도출해서 다시 성능을 내봐야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66074f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca601fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
